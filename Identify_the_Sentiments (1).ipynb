{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "name": "Identify the Sentiments.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfbaHBXiUFHe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "02150503-677d-4a3c-dfaa-87d168ba5395"
      },
      "source": [
        "pip uninstall tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.2.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.2.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDExR9irUMpd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "outputId": "92b65832-5808-4587-c799-2cd98e9f60f8"
      },
      "source": [
        "pip install tensorflow==1.13.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.13.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/d3/651f95288a6cd9094f7411cdd90ef12a3d01a268009e0e3cd66b5c8d65bd/tensorflow-1.13.2-cp36-cp36m-manylinux1_x86_64.whl (92.6MB)\n",
            "\u001b[K     |████████████████████████████████| 92.6MB 51kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.30.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.18.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.9.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.34.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.12.0)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 44.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.8.1)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 46.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.2) (47.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.2) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.2.2)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.1.0)\n",
            "Installing collected packages: tensorboard, mock, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "Successfully installed mock-4.0.2 tensorboard-1.13.1 tensorflow-1.13.2 tensorflow-estimator-1.13.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfKV7pA3T6YP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "985ad7a4-d179-4c00-92e6-1f6585d353dd"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.contrib import keras\n",
        "from tensorflow.contrib.keras import models\n",
        "from tensorflow.contrib.keras import datasets\n",
        "from tensorflow.contrib.keras import layers\n",
        "from tensorflow.contrib.keras import preprocessing\n",
        "from tensorflow.contrib.keras import backend as K\n",
        "from tensorflow.contrib.keras import callbacks\n",
        "from tensorflow.contrib.keras import utils\n",
        "\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import sys\n",
        "import random\n",
        "import glob\n",
        "from sklearn import metrics,model_selection\n",
        "import csv\n",
        "from collections import Counter\n",
        "import warnings\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "learn = tf.contrib.learn\n",
        "tf.logging.set_verbosity(tf.logging.WARN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tal0NK6LT6YY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_DOCUMENT_LENGTH=100#128#100\n",
        "maxlen_word=20#5#20\n",
        "num_classes=4\n",
        "embedding_dims=100\n",
        "filters=250\n",
        "kernel_size = 3\n",
        "hidden_dims = 100\n",
        "batch_size=128#5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV0xB4z5T6Yd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ann_dir= r\"/content/train_2kmZucJ.csv\" #set_combined_final\n",
        "\n",
        "duplicate_samples=1\n",
        "duplicate_samples_pos=1\n",
        "#n_files=60\n",
        "n_epoch=30\n",
        "f= open(\"report_sections_cnn_only_text_09_01_17_files_\"+\"_epoch_\"+str(n_epoch)+\".txt\",\"w\")\n",
        "#f.write(\"Number of files: \")\n",
        "#f.write(str(n_files))\n",
        "f.write(\"\\nNumber of epoch: \")\n",
        "f.write(str(n_epoch))\n",
        "f.write(\"\\n\")\n",
        "load_from_vector=False\n",
        "model_dir=\"cnn_only_text_section_header/\"\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReCm18MJT6Yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sh_dataset = defaultdict(lambda : None)\n",
        "sh_dataset['target_names'] = ['pos','neg']\n",
        "sh_dataset['target'] =[]\n",
        "sh_dataset['data'] =[]\n",
        "sh_dataset['layout'] =[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Nu8f2_8T6Yl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(ann_dir, 'rt',encoding=\"utf8\") as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    for row in reader:\n",
        "        for i in range(duplicate_samples):\n",
        "            if row['label'] =='0':\n",
        "                for j in range(duplicate_samples_pos):\n",
        "                    sh_dataset['target'].append(0)\n",
        "                    sh_dataset['data'].append(row['tweet'])\n",
        "            elif row['label'] =='1':\n",
        "                for j in range(duplicate_samples_pos):\n",
        "                    sh_dataset['target'].append(1)  \n",
        "                    sh_dataset['data'].append(row['tweet'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9-6moRZdJqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "51829c05-a62e-4b14-fe2e-11af60824a8f"
      },
      "source": [
        "row"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('id', '7920'),\n",
              "             ('label', '0'),\n",
              "             ('tweet',\n",
              "              'Apple Barcelona!!! #Apple #Store #BCN #Barcelona #travel #iphone #selfie #fly #fun #cabincrew… http://instagram.com/p/wBApVzpCl3/')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wLYvkHBT6Yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training data\n",
        "training_dataset = defaultdict(lambda : None)\n",
        "training_dataset['target_names'] =['pos','neg']\n",
        "training_dataset['target'] =[]\n",
        "training_dataset['data'] =[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yU8y7OwT6Ys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "03178a0d-fddf-43ee-b99b-c5ab2fd946ad"
      },
      "source": [
        "len(sh_dataset['data'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7920"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JrJ2T8bT6Y1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_sample = min(sh_dataset['target'].count(0),sh_dataset['target'].count(1))\n",
        "\n",
        "count_top_sample=0\n",
        "count_sub_sample=0\n",
        "count_subsub_sample=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0N18YLGT6Y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(sh_dataset['target'])):\n",
        "    if sh_dataset['target'][i]==0:\n",
        "        if count_top_sample<pos_sample:\n",
        "            training_dataset['data'].append(sh_dataset['data'][i])\n",
        "            training_dataset['target'].append(sh_dataset['target'][i])\n",
        "            count_top_sample+=1\n",
        "    elif sh_dataset['target'][i]==1:\n",
        "        if count_sub_sample<pos_sample:\n",
        "            training_dataset['data'].append(sh_dataset['data'][i])\n",
        "            training_dataset['target'].append(sh_dataset['target'][i])\n",
        "            count_sub_sample+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JUdqnKdT6ZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_dataset_ran = defaultdict(lambda : None)\n",
        "training_dataset_ran['target_names'] =['pos','neg']\n",
        "training_dataset_ran['target'] =[]\n",
        "training_dataset_ran['data'] =[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26WlUhAfT6ZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "ran_index= random.sample(range(0, len(training_dataset['data'])), len(training_dataset['data']))\n",
        "for i in ran_index:\n",
        "    training_dataset_ran['data'].append(training_dataset['data'][i])\n",
        "    training_dataset_ran['target'].append(training_dataset['target'][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6IrFNv6T6ZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del training_dataset   \n",
        "del sh_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yF2xGzCT6ZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Training\")\n",
        "f.write(\"Training\\n\")\n",
        "print(\"Heading\",training_dataset_ran[\"target\"].count(0))\n",
        "f.write(\"Top samples \")\n",
        "f.write(str(training_dataset_ran[\"target\"].count(1)))\n",
        "f.write(\"\\n\")\n",
        "print(\"Section Heading\",training_dataset_ran[\"target\"].count(1))\n",
        "f.write(\"Top samples \")\n",
        "f.write(str(training_dataset_ran[\"target\"].count(1)))\n",
        "f.write(\"\\n\")\n",
        "print(\"Sub - Heading\",training_dataset_ran[\"target\"].count(2))\n",
        "f.write(\"Sub samples \")\n",
        "f.write(str(training_dataset_ran[\"target\"].count(2)))\n",
        "f.write(\"\\n\")\n",
        "print(\"Sub-Sub Heading\",training_dataset_ran[\"target\"].count(3))\n",
        "f.write(\"Subsub samples \")\n",
        "f.write(str(training_dataset_ran[\"target\"].count(3)))\n",
        "f.write(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpoTdfiET6Za",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(sh_dataset['data'],sh_dataset['target'], test_size=0.2,random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXmCUoN_T6Zf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train=pd.DataFrame({'line':X_train,'class':y_train})\n",
        "df_train.to_csv(model_dir+\"stratified_training_50\", sep='\\t',index=False, encoding='utf-8')\n",
        "\n",
        "df_test=pd.DataFrame({'line':X_test,'class':y_test})\n",
        "df_test.to_csv(model_dir+\"stratified_test_10\", sep='\\t',index=False, encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV1Odj8WrkTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re,string\n",
        "\n",
        "def strip_links(text):\n",
        "    link_regex    = re.compile('((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)', re.DOTALL)\n",
        "    links         = re.findall(link_regex, text)\n",
        "    for link in links:\n",
        "        text = text.replace(link[0], ', ')    \n",
        "    return text\n",
        "def convert_vulgar(text):\n",
        "  words = []\n",
        "  for word in text.split():\n",
        "    if word=='$&@*#':\n",
        "      words.append('fuck')\n",
        "    else:\n",
        "      words.append(word)\n",
        "  return ' '.join(words)\n",
        "def strip_all_entities(text):\n",
        "    entity_prefixes = ['@']\n",
        "    words = []\n",
        "    for word in text.split():\n",
        "        word = word.strip()\n",
        "        if word:\n",
        "            if word[0] not in entity_prefixes:\n",
        "                words.append(word)\n",
        "    return ' '.join(words)\n",
        "def remove_hastag(text):\n",
        "  return text.replace('#', '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPKakOSOrxhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(X_train)):\n",
        "  X_train[i] = strip_all_entities(strip_links(remove_hastag(convert_vulgar(X_train[i]))))\n",
        "for i in range(len(X_test)):\n",
        "  X_test[i] = strip_all_entities(strip_links(remove_hastag(convert_vulgar(X_test[i]))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbRzp1DP4s9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "3adb13f0-320c-40f1-be1f-5f6325055df7"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def remove_stopwords(text):\n",
        "  word_tokens = word_tokenize(text)\n",
        "  Filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
        "  return ' '.join(Filtered_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCPqGny169uv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nltk\n",
        "nlp = spacy.load('en')\n",
        "def removing_name_entity(text):\n",
        "  document = nlp(text)\n",
        "  text_no_namedentities = []\n",
        "  ents = [e.text for e in document.ents]\n",
        "  for item in document:\n",
        "    if item.text in ents:\n",
        "        pass\n",
        "    else:\n",
        "        text_no_namedentities.append(item.text)\n",
        "  return \" \".join(text_no_namedentities)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xrw25RMxdjAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(X_train)):\n",
        "  X_train[i] = remove_stopwords(removing_name_entity(X_train[i]))\n",
        "for i in range(len(X_test)):\n",
        "  X_test[i] = remove_stopwords(removing_name_entity(X_test[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDwDy5L8T6Zm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Process vocabulary character level\n",
        "char_processor = learn.preprocessing.ByteProcessor(MAX_DOCUMENT_LENGTH)\n",
        "X_train_char = np.array(list(char_processor.fit_transform(X_train)))\n",
        "X_test_char = np.array(list(char_processor.transform(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDXchB1QT6Zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Process vocabulary world level\n",
        "vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(maxlen_word,min_frequency=100)\n",
        "X_train_word = np.array(list(vocab_processor.fit_transform(X_train)))\n",
        "X_test_word = np.array(list(vocab_processor.transform(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkA-XPUFT6Zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Class labels to categorical value\n",
        "# y_train = keras.utils.to_categorical(y_train,num_classes=num_classes)\n",
        "# y_test = keras.utils.to_categorical(y_test,num_classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdx8h-2sT6Z5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_words = len(vocab_processor.vocabulary_)\n",
        "max_char = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5iMQm6JT6Z9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2fb62010-1f3a-4818-a9ea-4ae79fddfd03"
      },
      "source": [
        "print(max_words)\n",
        "print(max_char)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104\n",
            "256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3JNQVMPpTh-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4fdffc9e-d9db-4440-b91e-fe4912d080ec"
      },
      "source": [
        "maxlen_word"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzVZJwEfT6aA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# char_CNN\n",
        "input_char =  layers.Input(shape=(MAX_DOCUMENT_LENGTH,), name = 'input_char')\n",
        "\n",
        "embedding_char= layers.Embedding(max_char,embedding_dims,input_length=MAX_DOCUMENT_LENGTH)(input_char)\n",
        "dropout1_char = layers.Dropout(0.2)(embedding_char)\n",
        "\n",
        "conv1D_char = layers.Conv1D(filters,\n",
        "                 kernel_size,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1)(dropout1_char)\n",
        "\n",
        "globalMaxPooling1_char= layers.GlobalMaxPooling1D()(conv1D_char)\n",
        "\n",
        "dense_hidden_char = layers.Dense(hidden_dims)(globalMaxPooling1_char)\n",
        "dropout2_char = layers.Dropout(0.2)(dense_hidden_char)\n",
        "activation_char= layers.Activation('relu')(dropout2_char)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReLt2OeGT6aF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main_output = layers.Dense(num_classes, activation='softmax', name='main_output')(activation_char)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KaBXCOVT6aI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Model(inputs=[input_char], outputs=[main_output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI_CggGYT6aN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "d4b2b555-24d3-4447-b90b-74ab0e1fec62"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_char (InputLayer)      (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "embedding_7 (Embedding)      (None, 100, 100)          25600     \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 100, 100)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 98, 250)           75250     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_7 (Glob (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 100)               25100     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "main_output (Dense)          (None, 4)                 404       \n",
            "=================================================================\n",
            "Total params: 126,354\n",
            "Trainable params: 126,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92t4dzpmT6aT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath=model_dir+\"weights-improvement-{epoch:02d}-{val_acc:.9f}.hdf5\"\n",
        "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='F1_score', verbose=1, save_best_only=True, mode='max')\n",
        "history = callbacks.History()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmIe36UVT6aX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "outputId": "837eb0b6-be91-48ee-bcd4-d054cfcce0b0"
      },
      "source": [
        "model.fit(X_train_char, y_train,\n",
        "          batch_size=batch_size,shuffle=True,\n",
        "          epochs=13,verbose=1,\n",
        "          validation_data=(X_test_char, y_test),callbacks=[checkpoint,history])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6336 samples, validate on 1584 samples\n",
            "Epoch 1/13\n",
            "6272/6336 [============================>.] - ETA: 0s - loss: 0.6510 - acc: 0.7414WARNING:tensorflow:Can save best model only with F1_score available, skipping.\n",
            "6336/6336 [==============================] - 13s 2ms/sample - loss: 0.6479 - acc: 0.7424 - val_loss: 0.4071 - val_acc: 0.8201\n",
            "Epoch 2/13\n",
            "6272/6336 [============================>.] - ETA: 0s - loss: 0.3907 - acc: 0.8224WARNING:tensorflow:Can save best model only with F1_score available, skipping.\n",
            "6336/6336 [==============================] - 13s 2ms/sample - loss: 0.3905 - acc: 0.8224 - val_loss: 0.3517 - val_acc: 0.8485\n",
            "Epoch 3/13\n",
            "6272/6336 [============================>.] - ETA: 0s - loss: 0.3329 - acc: 0.8584WARNING:tensorflow:Can save best model only with F1_score available, skipping.\n",
            "6336/6336 [==============================] - 13s 2ms/sample - loss: 0.3334 - acc: 0.8580 - val_loss: 0.3141 - val_acc: 0.8706\n",
            "Epoch 4/13\n",
            "6272/6336 [============================>.] - ETA: 0s - loss: 0.3031 - acc: 0.8732WARNING:tensorflow:Can save best model only with F1_score available, skipping.\n",
            "6336/6336 [==============================] - 13s 2ms/sample - loss: 0.3026 - acc: 0.8736 - val_loss: 0.3031 - val_acc: 0.8681\n",
            "Epoch 5/13\n",
            "6272/6336 [============================>.] - ETA: 0s - loss: 0.2877 - acc: 0.8779WARNING:tensorflow:Can save best model only with F1_score available, skipping.\n",
            "6336/6336 [==============================] - 13s 2ms/sample - loss: 0.2869 - acc: 0.8780 - val_loss: 0.2972 - val_acc: 0.8756\n",
            "Epoch 6/13\n",
            "6272/6336 [============================>.] - ETA: 0s - loss: 0.2792 - acc: 0.8819WARNING:tensorflow:Can save best model only with F1_score available, skipping.\n",
            "6336/6336 [==============================] - 13s 2ms/sample - loss: 0.2784 - acc: 0.8824 - val_loss: 0.2914 - val_acc: 0.8763\n",
            "Epoch 7/13\n",
            "6272/6336 [============================>.] - ETA: 0s - loss: 0.2610 - acc: 0.8917WARNING:tensorflow:Can save best model only with F1_score available, skipping.\n",
            "6336/6336 [==============================] - 13s 2ms/sample - loss: 0.2616 - acc: 0.8913 - val_loss: 0.2938 - val_acc: 0.8693\n",
            "Epoch 8/13\n",
            "6272/6336 [============================>.] - ETA: 0s - loss: 0.2507 - acc: 0.8962WARNING:tensorflow:Can save best model only with F1_score available, skipping.\n",
            "6336/6336 [==============================] - 13s 2ms/sample - loss: 0.2512 - acc: 0.8960 - val_loss: 0.2928 - val_acc: 0.8756\n",
            "Epoch 9/13\n",
            "6272/6336 [============================>.] - ETA: 0s - loss: 0.2358 - acc: 0.9050WARNING:tensorflow:Can save best model only with F1_score available, skipping.\n",
            "6336/6336 [==============================] - 13s 2ms/sample - loss: 0.2360 - acc: 0.9050 - val_loss: 0.2847 - val_acc: 0.8737\n",
            "Epoch 10/13\n",
            "6272/6336 [============================>.] - ETA: 0s - loss: 0.2272 - acc: 0.9070WARNING:tensorflow:Can save best model only with F1_score available, skipping.\n",
            "6336/6336 [==============================] - 13s 2ms/sample - loss: 0.2282 - acc: 0.9066 - val_loss: 0.2855 - val_acc: 0.8775\n",
            "Epoch 11/13\n",
            "6272/6336 [============================>.] - ETA: 0s - loss: 0.2161 - acc: 0.9128WARNING:tensorflow:Can save best model only with F1_score available, skipping.\n",
            "6336/6336 [==============================] - 13s 2ms/sample - loss: 0.2163 - acc: 0.9129 - val_loss: 0.2805 - val_acc: 0.8775\n",
            "Epoch 12/13\n",
            "6272/6336 [============================>.] - ETA: 0s - loss: 0.2005 - acc: 0.9200WARNING:tensorflow:Can save best model only with F1_score available, skipping.\n",
            "6336/6336 [==============================] - 13s 2ms/sample - loss: 0.2004 - acc: 0.9200 - val_loss: 0.2846 - val_acc: 0.8756\n",
            "Epoch 13/13\n",
            "6272/6336 [============================>.] - ETA: 0s - loss: 0.1898 - acc: 0.9257WARNING:tensorflow:Can save best model only with F1_score available, skipping.\n",
            "6336/6336 [==============================] - 15s 2ms/sample - loss: 0.1903 - acc: 0.9253 - val_loss: 0.2895 - val_acc: 0.8769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f556b099f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgnzm8pPTNlP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yhat_probs = model.predict(X_test_char, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ahT8_IOTLTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = []\n",
        "for i in np.arange(len(yhat_probs)):\n",
        "    y_pred.append(yhat_probs[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXnJ6oHWiviL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv('test_oJQbWVk.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L16yGtzDi-uM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = test['tweet']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K3_Vn99vCse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(X_test)):\n",
        "  x_test[i] = strip_all_entities(strip_links(remove_hastag(convert_vulgar(x_test[i]))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14WMmtyl3vxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(X_test)):\n",
        "  x_test[i] = remove_stopwords(removing_name_entity(x_test[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVQuZ07FjEBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_char = np.array(list(char_processor.transform(x_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2j8Vj6wjZ5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_words = np.array(list(vocab_processor.transform(x_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-eg8LACT6ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#confusion matrix\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "yhat_probs1 = model.predict(x_test_char, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGGiA87GT6ag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred1 = []\n",
        "for i in np.arange(len(yhat_probs1)):\n",
        "    y_pred1.append(yhat_probs1[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVxAYaIvIWG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C = pd.DataFrame()\n",
        "C1 = pd.DataFrame()\n",
        "C['f1'] = y_pred\n",
        "C1['f1'] = y_pred1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWVXmZxwJm0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C['f2'] = y_pred\n",
        "C1['f2'] = y_pred1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnJ2OB4UJvgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C['f3'] = y_pred\n",
        "C1['f3'] = y_pred1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKFscf0SNZCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C['f4'] = y_pred\n",
        "C1['f4'] = y_pred1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N96jA5JhOj8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C['f5'] = y_pred\n",
        "C1['f5'] = y_pred1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcUtOENuO758",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C['f6'] = y_pred\n",
        "C1['f6'] = y_pred1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyfN6gVqPb7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C['f7'] = y_pred\n",
        "C1['f7'] = y_pred1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi4Yxn9IPetk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C['f8'] = y_pred\n",
        "C1['f8'] = y_pred1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYZU2ms3R5TD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C['r'] = y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0_JmIqstj0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "08625a1e-bd0d-4ba1-cae2-2f403b662283"
      },
      "source": [
        "C"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>r</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.998416</td>\n",
              "      <td>0.607817</td>\n",
              "      <td>0.998116</td>\n",
              "      <td>0.999202</td>\n",
              "      <td>0.998680</td>\n",
              "      <td>0.971961</td>\n",
              "      <td>0.996768</td>\n",
              "      <td>0.999511</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.057165</td>\n",
              "      <td>0.157360</td>\n",
              "      <td>0.231886</td>\n",
              "      <td>0.052355</td>\n",
              "      <td>0.059222</td>\n",
              "      <td>0.175998</td>\n",
              "      <td>0.152385</td>\n",
              "      <td>0.042954</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.948777</td>\n",
              "      <td>0.748943</td>\n",
              "      <td>0.987241</td>\n",
              "      <td>0.964680</td>\n",
              "      <td>0.945628</td>\n",
              "      <td>0.680139</td>\n",
              "      <td>0.815134</td>\n",
              "      <td>0.309549</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.418235</td>\n",
              "      <td>0.435295</td>\n",
              "      <td>0.116457</td>\n",
              "      <td>0.137114</td>\n",
              "      <td>0.524201</td>\n",
              "      <td>0.104070</td>\n",
              "      <td>0.248611</td>\n",
              "      <td>0.437710</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.988883</td>\n",
              "      <td>0.812548</td>\n",
              "      <td>0.993853</td>\n",
              "      <td>0.976787</td>\n",
              "      <td>0.982364</td>\n",
              "      <td>0.869260</td>\n",
              "      <td>0.971748</td>\n",
              "      <td>0.965718</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1579</th>\n",
              "      <td>0.179476</td>\n",
              "      <td>0.718851</td>\n",
              "      <td>0.427883</td>\n",
              "      <td>0.073128</td>\n",
              "      <td>0.102843</td>\n",
              "      <td>0.773416</td>\n",
              "      <td>0.512399</td>\n",
              "      <td>0.115211</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1580</th>\n",
              "      <td>0.546571</td>\n",
              "      <td>0.907670</td>\n",
              "      <td>0.883691</td>\n",
              "      <td>0.735058</td>\n",
              "      <td>0.537632</td>\n",
              "      <td>0.843690</td>\n",
              "      <td>0.624340</td>\n",
              "      <td>0.712817</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1581</th>\n",
              "      <td>0.999154</td>\n",
              "      <td>0.889502</td>\n",
              "      <td>0.990393</td>\n",
              "      <td>0.999466</td>\n",
              "      <td>0.999819</td>\n",
              "      <td>0.848743</td>\n",
              "      <td>0.962125</td>\n",
              "      <td>0.997168</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1582</th>\n",
              "      <td>0.999822</td>\n",
              "      <td>0.950064</td>\n",
              "      <td>0.999170</td>\n",
              "      <td>0.999576</td>\n",
              "      <td>0.999893</td>\n",
              "      <td>0.991842</td>\n",
              "      <td>0.998986</td>\n",
              "      <td>0.998892</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1583</th>\n",
              "      <td>0.777609</td>\n",
              "      <td>0.908663</td>\n",
              "      <td>0.996205</td>\n",
              "      <td>0.772646</td>\n",
              "      <td>0.877759</td>\n",
              "      <td>0.985864</td>\n",
              "      <td>0.968557</td>\n",
              "      <td>0.734649</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1584 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            f1        f2        f3        f4  ...        f6        f7        f8  r\n",
              "0     0.998416  0.607817  0.998116  0.999202  ...  0.971961  0.996768  0.999511  0\n",
              "1     0.057165  0.157360  0.231886  0.052355  ...  0.175998  0.152385  0.042954  1\n",
              "2     0.948777  0.748943  0.987241  0.964680  ...  0.680139  0.815134  0.309549  0\n",
              "3     0.418235  0.435295  0.116457  0.137114  ...  0.104070  0.248611  0.437710  0\n",
              "4     0.988883  0.812548  0.993853  0.976787  ...  0.869260  0.971748  0.965718  0\n",
              "...        ...       ...       ...       ...  ...       ...       ...       ... ..\n",
              "1579  0.179476  0.718851  0.427883  0.073128  ...  0.773416  0.512399  0.115211  0\n",
              "1580  0.546571  0.907670  0.883691  0.735058  ...  0.843690  0.624340  0.712817  0\n",
              "1581  0.999154  0.889502  0.990393  0.999466  ...  0.848743  0.962125  0.997168  0\n",
              "1582  0.999822  0.950064  0.999170  0.999576  ...  0.991842  0.998986  0.998892  0\n",
              "1583  0.777609  0.908663  0.996205  0.772646  ...  0.985864  0.968557  0.734649  0\n",
              "\n",
              "[1584 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsCvx85nRnw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C.to_csv('125.csv')\n",
        "C1.to_csv('124.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEmbbEtseFPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvOBc9NLd2Ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C = pd.read_csv('125.csv')\n",
        "C1 = pd.read_csv('124.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C_rVxp1g5jI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C = C.iloc[:,1:]\n",
        "C1 = C1.iloc[:,1:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIj53qw8eNcU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGg5klkF7Web",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tr, x_te, y_tr, y_te = train_test_split(C.iloc[:,:-1],C.iloc[:,8], test_size=0.25,random_state = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sE6FS_h3lGE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "13a6c1c1-30fe-4e7c-959b-75bc2dae5771"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "model.fit(x_tr, y_tr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0smW0WmrLB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = model.predict_proba(x_te)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x2Uzsfds09I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y1 = model.predict_proba(C1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xazMIxhsrpTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = []\n",
        "for i in range(len(y)):\n",
        "    y_pred.append(y[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP2v1i3Fsze4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred1 = []\n",
        "for i in range(len(y1)):\n",
        "    y_pred1.append(y1[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNs9TVN8rSNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = pd.DataFrame()\n",
        "A1 = pd.DataFrame()\n",
        "A['f1'] = y_pred\n",
        "A1['f1'] = y_pred1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_V9uRsG-zFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model= RandomForestClassifier(n_estimators=1000)\n",
        "model.fit(x_tr, y_tr)\n",
        "y_p = model.predict_proba(x_te)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om4PwN3gtY2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y1 = model.predict_proba(C1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q1GFIuLtSCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = []\n",
        "for i in range(len(y_p)):\n",
        "    y_pred.append(y_p[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r9YqnQmtWDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred1 = []\n",
        "for i in range(len(y1)):\n",
        "    y_pred1.append(y1[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpBKqcrksPRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A['f2'] = y_pred\n",
        "A1['f2'] = y_pred1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2nl6RCAuz0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A['f3'] = y_pred\n",
        "A1['f3'] = y_pred1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTFNOODOlD_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(C1)\n",
        "for i in range(0,len(y_pred)):    \n",
        "  if y_pred[i]>=.5:         \n",
        "     y_pred[i]=1    \n",
        "  else:         \n",
        "    y_pred[i]=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2NbncmkneAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB(var_smoothing=1e-08)\n",
        "classifier.fit(x_tr, y_tr)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict_proba(x_te)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z5Z3uaOw4Ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred1 = classifier.predict_proba(C1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W17B-rPjzHBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = []\n",
        "for i in range(0,len(y_pred)):            \n",
        "     y.append(y_pred[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r3JmuFAzejP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y1 = []\n",
        "for i in range(0,len(y_pred1)):            \n",
        "     y1.append(y_pred1[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVqI28MGy3_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A['f4'] = y\n",
        "A1['f4'] = y1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOxGx2W1qTik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'linear', random_state = 0)\n",
        "classifier.fit(x_tr, y_tr)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(x_te)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMR4KoiG0lhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbWvm3V2zuXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred1 = classifier.predict(C1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHx0HV9Wz_Pv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A['f5'] = 1-y_pred\n",
        "A1['f5'] = 1-y_pred1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hFcU8t_91Av",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgb \n",
        "param = {'num_leaves':150, 'objective':'binary','max_depth':7,'learning_rate':.06,'max_bin':200} \n",
        "param['metric'] = ['auc', 'binary_logloss']\n",
        "num_round=50 \n",
        "train_data=lgb.Dataset(x_tr,label=y_tr)\n",
        "lgbm=lgb.train(param,train_data,num_round) \n",
        "ypred2=lgbm.predict(x_te)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4zFTXR91iPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A['f6'] = 1-ypred2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUXksny7R0ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = lgbm.predict(C1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSBvcAEw1wKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A1['f6'] = 1-y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "offyJz3_AsV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,len(y_pred)):    \n",
        "  if y_pred[i]>=.5:         \n",
        "     y_pred[i]=1    \n",
        "  else:         \n",
        "    y_pred[i]=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tetc1dI62D2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tr, x_te, y_tr, y_te = train_test_split(A,y_te, test_size=0.25,random_state = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAjLpewI14CW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "0dfca818-2782-4261-d8b0-0a2c2cf0792e"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "model.fit(x_tr, y_tr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqEfFuq3q8ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = model.predict_proba(x_te)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gbWWQ5n4bUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = []\n",
        "for i in range(0,len(y)):    \n",
        "  if y[i][0]>=.4775:         \n",
        "     z.append(0)    \n",
        "  else:         \n",
        "    z.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jxS0tXY24Be",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = model.predict_proba(A1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mV5HboMkVuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub = pd.DataFrame()\n",
        "sub['id'] = test['id']\n",
        "sub['label'] = z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgiaoYo8lMa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub.to_csv('sub31.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y1JMVqkT6ak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e6354a87-4c87-44db-8ce6-76d9ed211c53"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "cm = confusion_matrix(y_te, z)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[63,  9],\n",
              "       [ 4, 23]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Mkhg6HLq6iT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model= RandomForestClassifier(n_estimators=1000)\n",
        "model.fit(x_tr, y_tr)\n",
        "y_p = model.predict(x_te)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "077BHppFT6am",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "bf3a0f28-415e-4244-951a-66d778a81410"
      },
      "source": [
        "print(classification_report(y_te, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.87      0.92       285\n",
            "           1       0.73      0.92      0.82       111\n",
            "\n",
            "    accuracy                           0.88       396\n",
            "   macro avg       0.85      0.89      0.87       396\n",
            "weighted avg       0.90      0.88      0.89       396\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cG_1t_PT6ar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('./cnn_only_text_section_header/weights-improvement-20-0.824622512.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju-iZutkT6au",
        "colab_type": "code",
        "colab": {},
        "outputId": "52bed298-60df-4acb-8040-9b02043f3716"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98       304\n",
            "           1       0.84      0.64      0.73       120\n",
            "           2       0.65      0.46      0.54       144\n",
            "           3       0.74      0.91      0.82       293\n",
            "\n",
            "    accuracy                           0.82       861\n",
            "   macro avg       0.80      0.75      0.77       861\n",
            "weighted avg       0.82      0.82      0.82       861\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK_PP9DQT6bR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}